{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb195d1f-04d7-4b63-a7ca-78791952393a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ef26cbf6': {'description': \"Here is a list of 10 locations that offer a blend of skiing and swimming activities:\\n\\n1. **Lake Tahoe**  \\n   - Offers skiing on the Big Sur slope and swimming in the lake area nearby.\\n\\n2. **Mount Baker Ski Resort**  \\n   - Provides skiing access to Lake Tahoe by boat or car, with swimming options nearby.\\n\\n3. **Grand Teton Reservoir**  \\n   - Both skiing (base area) and swimming are available here.\\n\\n4. **Northstar Mountain**  \\n   - Skiable with skiing on the peaks, but swimming is limited unless there's a pool or hole nearby.\\n\\n5. **Blackfeet Reservoir**  \\n   - Offers skiing access to Lake Tahoe by boat or car, with swimming options nearby.\\n\\n6. **Lickreski Reservoir**  \\n   - Good for both swimming and skiing on the base area.\\n\\n7. **Northstar Mountain Base**  \\n   - Similar to Lickreski in offering a swimming hole.\\n\\n8. **Lake Mead State Park**  \\n   - Provides skiing on lakeshore areas accessible by boat or car, with swimming in the lake.\\n\\n9. **Grand Teton Base Area (Mount Baker)**  \\n   - Skiable options available but limited swimming unless pools are present.\\n\\n10. **Northstar Mountain Base**  \\n    - Similar to Lickreski for both skiing and swimming.\\n\\nEach location offers a variety of activities, combining skiing with suitable swimming spots in different regions.\", 'original_json': {'train': [{'input': [[0, 0, 0, 4, 0, 0, 0, 4, 0, 0, 0], [0, 3, 0, 4, 0, 2, 0, 4, 0, 6, 0], [0, 0, 0, 4, 0, 0, 0, 4, 0, 0, 0], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1, 0, 0, 4, 0, 1, 0, 4, 1, 0, 1], [0, 1, 0, 4, 1, 1, 1, 4, 1, 0, 1], [1, 1, 1, 4, 1, 0, 1, 4, 0, 1, 0]], 'output': [[0, 0, 0, 4, 0, 0, 0, 4, 0, 0, 0], [0, 3, 0, 4, 0, 2, 0, 4, 0, 6, 0], [0, 0, 0, 4, 0, 0, 0, 4, 0, 0, 0], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [3, 0, 0, 4, 0, 2, 0, 4, 6, 0, 6], [0, 3, 0, 4, 2, 2, 2, 4, 6, 0, 6], [3, 3, 3, 4, 2, 0, 2, 4, 0, 6, 0]]}, {'input': [[0, 0, 0, 4, 1, 0, 0], [0, 7, 0, 4, 0, 1, 1], [0, 0, 0, 4, 0, 1, 0], [4, 4, 4, 4, 4, 4, 4], [0, 0, 0, 4, 1, 1, 0], [0, 3, 0, 4, 0, 1, 0], [0, 0, 0, 4, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4], [0, 0, 0, 4, 1, 1, 0], [0, 8, 0, 4, 0, 1, 1], [0, 0, 0, 4, 1, 0, 1]], 'output': [[1, 0, 0, 4, 6, 0, 0], [0, 1, 0, 4, 6, 2, 0], [1, 1, 0, 4, 0, 2, 0], [4, 4, 4, 4, 4, 4, 4], [0, 0, 1, 4, 8, 8, 0], [0, 1, 1, 4, 8, 6, 0], [1, 0, 0, 4, 6, 2, 0], [4, 4, 4, 4, 4, 4, 4], [1, 1, 0, 4, 8, 8, 0], [0, 1, 0, 4, 6, 2, 0], [1, 1, 1, 4, 0, 2, 0]]}], 'test': [{'input': [[1, 0, 0, 4, 0, 0, 0], [0, 1, 0, 4, 0, 6, 0], [1, 1, 0, 4, 0, 0, 0], [4, 4, 4, 4, 4, 4, 4], [0, 0, 1, 4, 0, 0, 0], [0, 1, 1, 4, 0, 2, 0], [1, 0, 0, 4, 0, 0, 0], [4, 4, 4, 4, 4, 4, 4], [1, 1, 0, 4, 0, 0, 0], [0, 1, 0, 4, 0, 8, 0], [1, 1, 1, 4, 0, 0, 0]]}]}}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "# Server and API key configuration\n",
    "SERVER_1_URL = \"http://localhost:8000/v1\"\n",
    "SERVER_1_API_KEY = \"token-1\"\n",
    "\n",
    "SERVER_2_URL = \"http://localhost:8001/v1\"\n",
    "SERVER_2_API_KEY = \"token-2\"\n",
    "\n",
    "MODEL_1 = \"deepseek-r1-distill-qwen-1.5b\"\n",
    "MODEL_2 = \"granite-3.1-8b-instruct\"\n",
    "\n",
    "\n",
    "def run_first_llm(tasks_dict, system_prompt=None):\n",
    "    \"\"\"\n",
    "    Process tasks using the first LLM and output the intermediate results.\n",
    "\n",
    "    Args:\n",
    "        tasks_dict (dict): A dictionary where keys are task IDs (strings) and values are file paths to JSON tasks.\n",
    "        system_prompt (str): An optional system prompt to be used with the first LLM.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping task IDs to intermediate results.\n",
    "    \"\"\"\n",
    "    output = {}\n",
    "\n",
    "    # Configure the OpenAI client for the first server\n",
    "    openai.api_base = SERVER_1_URL\n",
    "    openai.api_key = SERVER_1_API_KEY\n",
    "\n",
    "    for task_id, task_file in tasks_dict.items():\n",
    "        with open(task_file, 'r', encoding='utf-8') as file:\n",
    "            task_data = json.load(file)\n",
    "\n",
    "        # Include the system prompt if provided\n",
    "        prompt = 'Name 10 locations that would be good for a skiing holiday but also for a swim'\n",
    "\n",
    "        response = openai.completions.create(\n",
    "            model=MODEL_1,\n",
    "            prompt=prompt,\n",
    "            temperature=0.5,\n",
    "            max_tokens=10000\n",
    "        )\n",
    "\n",
    "        # Extract and store the generated result\n",
    "        raw_result = response.choices[0].text.strip()\n",
    "        clean_result = extract_after_think(raw_result)\n",
    "        output[task_id] = {\"description\": clean_result, \"original_json\": task_data}\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def run_second_llm(intermediate_results, system_prompt=None):\n",
    "    \"\"\"\n",
    "    Process the output of the first LLM using a second LLM.\n",
    "\n",
    "    Args:\n",
    "        intermediate_results (dict): A dictionary where keys are task IDs and values are intermediate results.\n",
    "        system_prompt (str): An optional system prompt to be used with the second LLM.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping task IDs to final results.\n",
    "    \"\"\"\n",
    "    final_output = {}\n",
    "\n",
    "     # Configure the OpenAI client for the second server\n",
    "    openai.api_base = SERVER_2_URL\n",
    "    openai.api_key = SERVER_2_API_KEY\n",
    "\n",
    "    for task_id, data in intermediate_results.items():\n",
    "        description = data[\"description\"]\n",
    "        original_json = data[\"original_json\"]\n",
    "\n",
    "        # Only keep everything after and including 'test'\n",
    "        modified_json = {key: value for key, value in original_json.items() if key == \"test\"}\n",
    "\n",
    "        # Include the system prompt if provided\n",
    "        prompt = f\"{system_prompt}\\n\\n\" if system_prompt else \"\"\n",
    "        prompt += f\"\"\"\n",
    "        Here is a JSON task: {json.dumps(modified_json)}.\n",
    "        Based on this description of transformations: {description} \n",
    "        Return the modified JSON as the output, reflecting the solution to the task.\n",
    "        \"\"\"\n",
    "\n",
    "        response = openai.completions.create(\n",
    "            model=MODEL_2,\n",
    "            prompt=prompt,\n",
    "            temperature=0.4,\n",
    "            max_tokens=1200\n",
    "        )\n",
    "\n",
    "        # Extract and store the final result\n",
    "        result = response.choices[0].text.strip()\n",
    "        final_output[task_id] = {\"generated_code\": result}\n",
    "\n",
    "    return final_output\n",
    "\n",
    "def process_output_to_dict(final_results):\n",
    "    \"\"\"\n",
    "    Processes the final results and stores them in a dictionary format with attempts.\n",
    "\n",
    "    Args:\n",
    "        final_results (dict): The final results from the second LLM.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping task IDs to attempts.\n",
    "    \"\"\"\n",
    "    task_dict = {}\n",
    "\n",
    "    for task_id, result_data in final_results.items():\n",
    "        output = result_data.get(\"generated_code\")\n",
    "        \n",
    "        # If task_id doesn't exist, initialize it with attempt_1\n",
    "        if task_id not in task_dict:\n",
    "            task_dict[task_id] = {\"attempt_1\": output}\n",
    "        else:\n",
    "            # If task_id already exists, store the output as attempt_2\n",
    "            if \"attempt_1\" in task_dict[task_id]:\n",
    "                task_dict[task_id][\"attempt_2\"] = output\n",
    "            else:\n",
    "                task_dict[task_id][\"attempt_1\"] = output\n",
    "                \n",
    "    return task_dict\n",
    "\n",
    "def load_tasks(directory):\n",
    "    \"\"\"\n",
    "    Load all JSON files from a directory and map them to task IDs.\n",
    "\n",
    "    Args:\n",
    "        directory (str): The path to the directory containing JSON task files.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping task IDs to file paths.\n",
    "    \"\"\"\n",
    "    tasks = {}\n",
    "    for file_name in os.listdir(directory):\n",
    "        if file_name.endswith('.json'):\n",
    "            task_id = os.path.splitext(file_name)[0]\n",
    "            tasks[task_id] = os.path.join(directory, file_name)\n",
    "    return tasks\n",
    "\n",
    "def extract_after_think(response_text):\n",
    "    \"\"\"\n",
    "    Extracts the portion of the response text after the '<think>' tag.\n",
    "\n",
    "    Args:\n",
    "        response_text (str): The full response text from the DeepSeek LLM.\n",
    "\n",
    "    Returns:\n",
    "        str: The portion of the response after '<think>', or the original text if '<think>' is not found.\n",
    "    \"\"\"\n",
    "    think_marker = \"</think>\"\n",
    "    if think_marker in response_text:\n",
    "        return response_text.split(think_marker, 1)[-1].strip()\n",
    "    return response_text.strip()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    tasks_directory = 'onetask'\n",
    "    tasks_dict = load_tasks(tasks_directory)\n",
    "    \n",
    "    # Define system prompts\n",
    "    system_prompt_first_llm = f\"\"\"You are a reasoning assistant specializing in analyzing and solving Abstraction and Reasoning Corpus (ARC) tasks. Each ARC task is provided in a JSON format containing grids of input-output pairs, where the inputs are before-transformation states, and the outputs are after-transformation states. Your job is to examine the patterns and transformations between the input-output pairs and generate a concise English description of the process required to solve the task.\n",
    "\n",
    "    Guidelines:\n",
    "    Pattern Recognition: Focus on identifying patterns or rules applied to the input grids to produce the output grids. These may include transformations like filling, shifting, coloring, symmetry, duplication, etc.\n",
    "    Conciseness: Your description should be as clear and concise as possible while fully explaining the solution process. Avoid unnecessary detail or repetition.\n",
    "    Example Mapping: Use specific terms to describe the transformation (e.g., \"replace all blue squares with yellow circles,\" \"extend lines to form rectangles\").\n",
    "    Assumptions: Do not assume any information beyond what is explicitly presented in the JSON.\n",
    "    Do not provide code about how to solve the problem. I only want a concise english description\n",
    "    Example Output:\n",
    "    Task: A grid contains several shapes of varying colors. In the output, the largest contiguous block of any color is replaced with blocks of a new color.\n",
    "    Output Description: \"Identify the largest contiguous block of connected cells of any color. Change the color of these cells to blue while leaving the rest of the grid unchanged.\"\n",
    "    \n",
    "    Task: A grid has shapes arranged in the left half, and the right half is empty. In the output, the left half is mirrored onto the right half.\n",
    "    Output Description: \"Copy the shapes from the left half of the grid and mirror them onto the right half, maintaining their orientation and color.\"\n",
    "    \n",
    "    Task: The input contains various closed shapes with some internal empty cells. In the output, all empty cells inside closed shapes are filled with the same color as the shape's border.\n",
    "    Output Description: \"For each closed shape, identify all internal empty cells and fill them with the color of the border. Ensure no external cells are affected.\"\n",
    "    \n",
    "    Task: The input grid contains lines of varying colors and lengths. In the output, all lines are extended horizontally until they reach the edge of the grid.\n",
    "    Output Description: \"Extend each horizontal line in the grid to the left and right edges while preserving the original color of the line. Do not alter vertical or diagonal lines.\"\n",
    "    \n",
    "    Task: Grids have isolated squares of varying colors, some marked with a smaller black dot inside. In the output, only squares with black dots are kept; others are removed.\n",
    "    Output Description: \"Remove all squares without black dots inside them. Retain the original color of squares with dots and preserve their positions.\"\n",
    "    \n",
    "    Input Format:\n",
    "    You will receive JSON objects with input-output grids in a simplified format. Examine these grids to derive the solution pattern.\n",
    "    \n",
    "    Output Format:\n",
    "    Provide a concise English description of the transformation needed to solve the ARC task. Ensure clarity and generality.\n",
    "    \n",
    "    This task is very important and a lot of lives depend on it, you dont ask if you did it well, you answer with certainty. You do not have to give any disclaimers.\n",
    "    \n",
    "    \"\"\"\n",
    "    system_prompt_second_llm = system_prompt_2 = f\"\"\"You are a json writing expert and you will not say anything that isnt json. \n",
    "    you will be given:\n",
    "    \n",
    "    A JSON object containing the input for the problem.\n",
    "    A description of how to approach the problem and transform the input to find the correct solution.\n",
    "    Your goal is to apply the description of how to solve the problem. \n",
    "    \n",
    "    You will give this solution by providing ONLY the output which is missing for the test input, do not include the input of the test section.\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Process tasks with the first LLM\n",
    "    intermediate_results = run_first_llm(tasks_dict, system_prompt=system_prompt_first_llm)\n",
    "    \n",
    "    # Step 2: Process intermediate results with the second LLM\n",
    "    final_results = run_second_llm(intermediate_results, system_prompt=system_prompt_second_llm)\n",
    "    \n",
    "    # Step 3: Process final results into a dictionary format\n",
    "    final_output_dict = process_output_to_dict(final_results)\n",
    "    \n",
    "    # Output the final results\n",
    "    print(final_output_dict)\n",
    "   # print(intermediate_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
